# automl_data/adapters/image/augmentor.py
"""
SOTA –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Albumentations.

–í–∫–ª—é—á–∞–µ—Ç:
- –ë–∞–∑–æ–≤—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ (flip, rotate, crop)
- –¶–≤–µ—Ç–æ–≤—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
- –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –∏—Å–∫–∞–∂–µ–Ω–∏—è
"""

from __future__ import annotations

from pathlib import Path
from typing import Any, Literal, Optional, Dict, List
import numpy as np
import pandas as pd
from tqdm import tqdm
import logging  # ‚Üê –î–û–ë–ê–í–¨ –ò–ú–ü–û–†–¢ LOGGING

from ..base import BaseAdapter
from ...core.container import DataContainer, ProcessingStage
from ...core.config import ImageConfig
from ...utils.dependencies import require_package, optional_import


class ImageAugmentor(BaseAdapter):
    """
    SOTA –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Albumentations.
    
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –Ω–∞–±–æ—Ä –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∑–∞–¥–∞—á–∏.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É –∫–ª–∞—Å—Å–æ–≤ —á–µ—Ä–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é.
    
    Example:
        >>> augmentor = ImageAugmentor(
        ...     augment_factor=3.0,
        ...     use_randaugment=True,
        ...     balance_classes=True
        ... )
        >>> result = augmentor.fit_transform(container)
    """
    
    def __init__(
        self,
        config: ImageConfig | None = None,
        augment_factor: float = 3.0,
        balance_classes: bool = True,
        
        # –ë–∞–∑–æ–≤—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        horizontal_flip: bool = True,
        vertical_flip: bool = False,
        rotation_range: int = 15,
        
        # –¶–≤–µ—Ç–æ–≤—ã–µ
        brightness_range: tuple[float, float] = (0.8, 1.2),
        contrast_range: tuple[float, float] = (0.8, 1.2),
        saturation_range: tuple[float, float] = (0.8, 1.2),
        hue_range: float = 0.1,
        
        # –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ
        zoom_range: tuple[float, float] = (0.9, 1.1),
        shift_range: float = 0.1,
        shear_range: float = 0.1,
        
        # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ
        use_randaugment: bool = True,
        use_mixup: bool = False,
        use_cutmix: bool = False,
        use_cutout: bool = True,
        
        # –®—É–º –∏ –±–ª—é—Ä
        add_noise: bool = True,
        add_blur: bool = True,
        
        output_dir: Path | None = None,
        random_state: int = 42,
        
        verbose: bool = True,  # ‚Üê –î–û–ë–ê–í–¨ –ü–ê–†–ê–ú–ï–¢–† VERBOSE –í __init__
        save_examples: bool = True,
        examples_dir: Path | None = None,
        n_examples: int = 10,
        **kwargs
    ):
        super().__init__(name="ImageAugmentor", **kwargs)
        
        # –ò–ù–ò–¶–ò–ê–õ–ò–ó–ò–†–£–ï–ú –õ–û–ì–ì–ï–†
        self._logger = logging.getLogger(f"automl_data.ImageAugmentor")
        self.verbose = verbose  # ‚Üê –°–û–•–†–ê–ù–Ø–ï–ú VERBOSE
        
        if config:
            self.augment_factor = config.augment_factor
            self.balance_classes = config.balance_classes
            self.horizontal_flip = config.horizontal_flip
            self.vertical_flip = config.vertical_flip
            self.rotation_range = config.rotation_range
            self.brightness_range = config.brightness_range
            self.contrast_range = config.contrast_range
            self.zoom_range = config.zoom_range
            self.use_randaugment = config.use_randaugment
            self.use_mixup = config.use_mixup
            self.use_cutmix = config.use_cutmix
        else:
            self.augment_factor = augment_factor
            self.balance_classes = balance_classes
            self.horizontal_flip = horizontal_flip
            self.vertical_flip = vertical_flip
            self.rotation_range = rotation_range
            self.brightness_range = brightness_range
            self.contrast_range = contrast_range
            self.zoom_range = zoom_range
            self.use_randaugment = use_randaugment
            self.use_mixup = use_mixup
            self.use_cutmix = use_cutmix
        
        self.saturation_range = saturation_range
        self.hue_range = hue_range
        self.shift_range = shift_range
        self.shear_range = shear_range
        self.use_cutout = use_cutout
        self.add_noise = add_noise
        self.add_blur = add_blur
        
        self.output_dir = Path(output_dir) if output_dir else None
        self.random_state = random_state
        
        self._transform = None
        self._class_counts: dict = {}
        self._target_count: int = 0
        self._logs: List[str] = []  # ‚Üê –î–õ–Ø –•–†–ê–ù–ï–ù–ò–Ø –õ–û–ì–û–í
        self._augmented_info: Dict[int, Dict] = {}  # ‚Üê –î–õ–Ø –û–¢–°–õ–ï–ñ–ò–í–ê–ù–ò–Ø –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–ô

        self.save_examples = save_examples
        self.examples_dir = Path(examples_dir) if examples_dir else None
        self.n_examples = n_examples
        self._examples: list[dict] = []
        
        np.random.seed(self.random_state)
    
    def _fit_impl(self, container: DataContainer) -> None:
        require_package("albumentations", "albumentations")
        require_package("cv2", "opencv-python")
        
        import albumentations as A
        
        np.random.seed(self.random_state)
        
        if self.verbose:
            self._log("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π...")
        
        # –°–æ–±–∏—Ä–∞–µ–º pipeline –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π
        transforms = []
        
        # –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ
        if self.horizontal_flip:
            transforms.append(A.HorizontalFlip(p=0.5))
        
        if self.vertical_flip:
            transforms.append(A.VerticalFlip(p=0.5))
        
        if self.rotation_range > 0:
            transforms.append(A.Rotate(
                limit=self.rotation_range, 
                p=0.5,
                border_mode=0
            ))
        
        if self.shift_range > 0 or self.zoom_range != (1.0, 1.0):
            transforms.append(A.ShiftScaleRotate(
                shift_limit=self.shift_range,
                scale_limit=(self.zoom_range[0] - 1, self.zoom_range[1] - 1),
                rotate_limit=0,
                p=0.5,
                border_mode=0
            ))
        
        if self.shear_range > 0:
            transforms.append(A.Affine(
                shear=(-self.shear_range * 45, self.shear_range * 45),
                p=0.3
            ))
        
        # –¶–≤–µ—Ç–æ–≤—ã–µ
        transforms.append(A.OneOf([
            A.RandomBrightnessContrast(
                brightness_limit=(self.brightness_range[0] - 1, self.brightness_range[1] - 1),
                contrast_limit=(self.contrast_range[0] - 1, self.contrast_range[1] - 1),
                p=1.0
            ),
            A.ColorJitter(
                brightness=0.2,
                contrast=0.2,
                saturation=0.2,
                hue=self.hue_range,
                p=1.0
            ),
        ], p=0.5))
        
        # RandAugment-style
        if self.use_randaugment:
            transforms.append(A.OneOf([
                A.Equalize(p=1.0),
                A.Posterize(p=1.0),
                A.Solarize(threshold=128, p=1.0),
                A.Sharpen(p=1.0),
                A.Emboss(p=1.0),
            ], p=0.3))
        
        # –®—É–º –∏ –±–ª—é—Ä
        if self.add_noise:
            transforms.append(A.OneOf([
                A.GaussNoise(var_limit=(10, 50), p=1.0),
                A.ISONoise(p=1.0),
            ], p=0.2))
        
        if self.add_blur:
            transforms.append(A.OneOf([
                A.MotionBlur(blur_limit=3, p=1.0),
                A.GaussianBlur(blur_limit=3, p=1.0),
            ], p=0.2))
        
        # Cutout
        if self.use_cutout:
            transforms.append(A.CoarseDropout(
                max_holes=8,
                max_height=32,
                max_width=32,
                min_holes=1,
                min_height=8,
                min_width=8,
                fill_value=0,
                p=0.3
            ))
        
        self._transform = A.Compose(transforms)
        
        # –ü–æ–¥—Å—á—ë—Ç –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        if self.balance_classes and container.target_column:
            self._class_counts = container.data[container.target_column].value_counts().to_dict()
            self._target_count = max(self._class_counts.values())
            
            if self.verbose:
                self._log(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏:")
                for cls, count in self._class_counts.items():
                    self._log(f"   ‚Ä¢ –ö–ª–∞—Å—Å {cls}: {count} (–Ω—É–∂–Ω–æ –¥–æ {self._target_count})")
        
        self._fit_info = {
            "n_transforms": len(transforms),
            "augment_factor": self.augment_factor,
            "balance_classes": self.balance_classes
        }
        
        if self.verbose:
            self._log(f"‚úÖ –°–æ–∑–¥–∞–Ω pipeline —Å {len(transforms)} —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è–º–∏")
    
    def _transform_impl(self, container: DataContainer) -> DataContainer:
        if not container.image_column or self._transform is None:
            self._log("‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é: –Ω–µ—Ç image_column –∏–ª–∏ transform", level="warning")
            return container
        
        if self.verbose:
            self._log("üîß –ù–∞—á–∏–Ω–∞—é –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
            self._log(f"   ‚Ä¢ balance_classes: {self.balance_classes}")
            self._log(f"   ‚Ä¢ augment_factor: {self.augment_factor}")
            self._log(f"   ‚Ä¢ –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(container.data)}")
        
        import cv2
        
        df = container.data.copy()
        image_col = container.image_column
        target_col = container.target_column
        image_dir = container.image_dir
        
        # –°–æ–∑–¥–∞—ë–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        if self.output_dir:
            self.output_dir.mkdir(parents=True, exist_ok=True)
            aug_dir = self.output_dir / "augmented"
            aug_dir.mkdir(exist_ok=True)
        else:
            aug_dir = None
        
        augmented_rows = []
        aug_counter = 0
        self._augmented_info.clear()  # ‚Üê –û–ß–ò–©–ê–ï–ú –ò–ù–§–û–†–ú–ê–¶–ò–Æ –û –ü–†–ï–î–´–î–£–©–ò–• –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–Ø–•
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∫–æ–ª—å–∫–æ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π –Ω—É–∂–Ω–æ
        if self.balance_classes and target_col and self._class_counts:
            if self.verbose:
                self._log("üìä –†–µ–∂–∏–º: –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤")
                self._log(f"   ‚Ä¢ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {self._class_counts}")
                self._log(f"   ‚Ä¢ –¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Å–∞: {self._target_count}")
            
            # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ —á–µ—Ä–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é
            for label, count in self._class_counts.items():
                class_df = df[df[target_col] == label]
                n_to_generate = self._target_count - count
                
                if n_to_generate > 0:
                    if self.verbose:
                        self._log(f"   ‚Ä¢ –ö–ª–∞—Å—Å {label}: –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å {n_to_generate} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                    
                    generated, aug_counter = self._augment_class(
                        class_df, image_col, image_dir, aug_dir,
                        n_to_generate, aug_counter, original_df=df
                    )
                    
                    if generated:
                        augmented_rows.extend(generated)
                        if self.verbose:
                            self._log(f"   ‚Ä¢ –ö–ª–∞—Å—Å {label}: –¥–æ–±–∞–≤–ª–µ–Ω–æ {len(generated)} –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö")
                    else:
                        if self.verbose:
                            self._log(f"   ‚Ä¢ –ö–ª–∞—Å—Å {label}: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        else:
            # –ü—Ä–æ—Å—Ç–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è
            if self.verbose:
                self._log("üìä –†–µ–∂–∏–º: –ü—Ä–æ—Å—Ç–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è")
            
            n_to_generate = max(0, int(len(df) * (self.augment_factor - 1)))
            if n_to_generate > 0:
                if self.verbose:
                    self._log(f"   ‚Ä¢ –ù—É–∂–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å: {n_to_generate} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                
                generated, aug_counter = self._augment_class(
                    df, image_col, image_dir, aug_dir,
                    n_to_generate, aug_counter, original_df=df
                )
                
                if generated:
                    augmented_rows.extend(generated)
                    if self.verbose:
                        self._log(f"   ‚Ä¢ –î–æ–±–∞–≤–ª–µ–Ω–æ: {len(generated)} –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ï –∏ –ê–£–ì–ú–ï–ù–¢–ò–†–û–í–ê–ù–ù–´–ï –¥–∞–Ω–Ω—ã–µ
        if augmented_rows:
            if self.verbose:
                self._log(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(augmented_rows)} –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            
            # –°–æ–∑–¥–∞—ë–º DataFrame –∏–∑ –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫
            aug_df = pd.DataFrame(augmented_rows)
            
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —É –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –µ—Å—Ç—å –í–°–ï –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ df
            for col in df.columns:
                if col not in aug_df.columns and col != '_augmented':
                    # –ö–æ–ø–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫
                    def get_original_value(row):
                        source_idx = row.get('_source_idx', -1)
                        if 0 <= source_idx < len(df):
                            return df.iloc[source_idx][col]
                        # –ï—Å–ª–∏ –Ω–µ—Ç source_idx, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –ø–æ –¥—Ä—É–≥–∏–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º
                        for key in ['image_path', 'image_id']:
                            if key in row and key in df.columns:
                                matching = df[df[key] == row[key]]
                                if len(matching) > 0:
                                    return matching.iloc[0][col]
                        return None
                    
                    aug_df[col] = aug_df.apply(get_original_value, axis=1)
            
            # –ì–ê–†–ê–ù–¢–ò–†–£–ï–ú –ù–ê–õ–ò–ß–ò–ï –ö–û–õ–û–ù–ö–ò _augmented:
            # 1. –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ - _augmented = False
            df['_augmented'] = False
            
            # 2. –ê—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ - _augmented = True
            aug_df['_augmented'] = True
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
            aug_df['_augmentation_info'] = aug_df.apply(
                lambda row: self._augmented_info.get(len(df) + row.name, {}) 
                if row.name in self._augmented_info else {},
                axis=1
            )
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º
            combined_df = pd.concat([df, aug_df], ignore_index=True)
            
            # –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ container
            container.data = combined_df
            container.stage = ProcessingStage.AUGMENTED
            
            if self.verbose:
                self._log(f"üìà –ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä: {len(container.data)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                self._log(f"   ‚Ä¢ –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö: {len(df)}")
                self._log(f"   ‚Ä¢ –ê—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö: {len(aug_df)}")
            
            if aug_dir:
                container.image_dir = aug_dir.parent
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
            container.metadata['augmentation'] = {
                'original_size': len(df),
                'augmented_size': len(aug_df),
                'total_size': len(container.data),
                'augment_factor': self.augment_factor,
                'balance_classes': self.balance_classes
            }
            
            container.recommendations.append({
                "type": "success",
                "message": f"–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ. –î–æ–±–∞–≤–ª–µ–Ω–æ {len(aug_df)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
                "original_size": len(df),
                "augmented_size": len(container.data),
                "output_dir": str(aug_dir) if aug_dir else None
            })
            
        else:
            if self.verbose:
                self._log("‚ö†Ô∏è –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–µ –¥–æ–±–∞–≤–∏–ª–∞ –Ω–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            # –ü–æ–º–µ—á–∞–µ–º –≤—Å–µ –∫–∞–∫ –Ω–µ –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
            df['_augmented'] = False
            container.data = df
            
            container.recommendations.append({
                "type": "warning",
                "message": "–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–µ –¥–æ–±–∞–≤–∏–ª–∞ –Ω–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.",
                "reason": "augmented_rows –ø—É—Å—Ç–æ–π"
            })
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π
        if self.save_examples and self._transform is not None:
            self._save_augmentation_examples(container)
        
        return container
    
    def _save_augmentation_examples(self, container: DataContainer):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
        import cv2
        
        if self.examples_dir:
            examples_dir = self.examples_dir / "augmentation_examples"
            examples_dir.mkdir(parents=True, exist_ok=True)
        else:
            examples_dir = Path("augmentation_examples")
            examples_dir.mkdir(exist_ok=True)
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏ –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
        if '_augmented' in container.data.columns:
            original_df = container.data[~container.data['_augmented']]
        else:
            original_df = container.data
        
        # –ë–µ—Ä—ë–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        n_samples = min(self.n_examples, len(original_df))
        if n_samples == 0:
            return
        
        sample_indices = np.random.choice(len(original_df), size=n_samples, replace=False)
        
        self._examples = []
        
        for i, idx in enumerate(sample_indices):
            row = original_df.iloc[idx]
            
            if container.image_column and container.image_column in row:
                img_path = Path(row[container.image_column])
                if container.image_dir:
                    img_path = container.image_dir / img_path
                
                if img_path.exists():
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
                    img = cv2.imread(str(img_path))
                    if img is not None:
                        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                        
                        # –°–æ–∑–¥–∞—ë–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π
                        for aug_idx in range(3):
                            augmented = self._transform(image=img_rgb)["image"]
                            
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
                            filename = f"example_{i:02d}_aug{aug_idx}.jpg"
                            save_path = examples_dir / filename
                            cv2.imwrite(
                                str(save_path),
                                cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR)
                            )
                            
                            self._examples.append({
                                "original": str(img_path),
                                "augmented": str(save_path),
                                "label": row.get(container.target_column, "") if container.target_column else "",
                                "index": i,
                                "augmentation": aug_idx
                            })
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        if self._examples:
            examples_df = pd.DataFrame(self._examples)
            examples_df.to_csv(examples_dir / "examples_metadata.csv", index=False)
            
            if self.verbose:
                self._log(f"üì∏ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(self._examples)} –ø—Ä–∏–º–µ—Ä–æ–≤ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π –≤ {examples_dir}")
            
            container.recommendations.append({
                "type": "visualization",
                "message": f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(self._examples)} –ø—Ä–∏–º–µ—Ä–æ–≤ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π",
                "examples_dir": str(examples_dir),
                "examples_count": len(self._examples)
            })

    def _log(self, message: str, level: str = "info"):
        """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        self._logs.append(message)
        
        if not self.verbose:
            return
        
        if level == "info":
            print(f"   [ImageAugmentor] {message}")
        elif level == "warning":
            print(f"   ‚ö†Ô∏è [ImageAugmentor] {message}")
        elif level == "debug":
            self._logger.debug(message)
        else:
            print(f"   [{level.upper()}] [ImageAugmentor] {message}")
    
    def get_examples(self) -> list[dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π"""
        return self._examples
    
    def get_augmentation_stats(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        return {
            'augmented_count': len(self._augmented_info),
            'logs': self._logs[-10:],  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –ª–æ–≥–æ–≤
            'verbose': self.verbose
        }
    
    def get_augmented_info(self) -> Dict[int, Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö"""
        return self._augmented_info.copy()
    
    def plot_examples(self, n: int = 4):
        """–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π"""
        if not self._examples:
            print("–ü—Ä–∏–º–µ—Ä—ã –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ save_examples=True")
            return
        
        import matplotlib.pyplot as plt
        import cv2
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
        examples_by_original = {}
        for ex in self._examples:
            key = ex['original']
            if key not in examples_by_original:
                examples_by_original[key] = []
            examples_by_original[key].append(ex)
        
        n = min(n, len(examples_by_original))
        orig_keys = list(examples_by_original.keys())[:n]
        
        fig, axes = plt.subplots(n, 4, figsize=(15, 3 * n))
        
        if n == 1:
            axes = axes.reshape(1, -1)
        
        for i, orig_key in enumerate(orig_keys):
            orig_examples = examples_by_original[orig_key]
            orig_example = orig_examples[0]
            
            # –û—Ä–∏–≥–∏–Ω–∞–ª
            orig_img = cv2.imread(orig_example["original"])
            if orig_img is not None:
                orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)
                
                axes[i, 0].imshow(orig_img)
                axes[i, 0].set_title(f"–û—Ä–∏–≥–∏–Ω–∞–ª\n{orig_example['label']}")
                axes[i, 0].axis('off')
                
                # 3 –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
                for j in range(3):
                    if j < len(orig_examples):
                        aug_example = orig_examples[j]
                        aug_img = cv2.imread(aug_example["augmented"])
                        if aug_img is not None:
                            aug_img = cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB)
                            
                            axes[i, j + 1].imshow(aug_img)
                            axes[i, j + 1].set_title(f"–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è {j + 1}")
                            axes[i, j + 1].axis('off')
        
        plt.suptitle("–ü—Ä–∏–º–µ—Ä—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", fontsize=16)
        plt.tight_layout()
        plt.savefig("augmentation_examples_plot.jpg", dpi=150, bbox_inches='tight')
        plt.show()
    
    def _augment_class(
        self,
        df: pd.DataFrame,
        image_col: str,
        image_dir: Path | None,
        output_dir: Path | None,
        n_samples: int,
        counter: int,
        original_df: Optional[pd.DataFrame] = None  # ‚Üê –î–û–ë–ê–í–ò–õ –û–ü–¶–ò–û–ù–ê–õ–¨–ù–´–ô –ü–ê–†–ê–ú–ï–¢–†
    ) -> tuple[list[dict], int]:
        """–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞ —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º"""
        import cv2
        
        augmented = []
        
        if len(df) == 0:
            return augmented, counter
        
        indices = np.random.choice(len(df), size=n_samples, replace=True)
        
        for i, idx in enumerate(indices):
            row = df.iloc[idx].to_dict()
            original_idx = df.index[idx]
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img_path = Path(row[image_col])
            if image_dir:
                img_path = image_dir / img_path
            
            img = cv2.imread(str(img_path))
            if img is None:
                continue
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º BGR -> RGB –¥–ª—è albumentations
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
            augmented_img = self._transform(image=img)["image"]
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ RGB -> BGR
            augmented_img = cv2.cvtColor(augmented_img, cv2.COLOR_RGB2BGR)
            
            # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
            new_row = row.copy()
            
            # –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–æ–±–∞–≤–ª—è–µ–º source_idx –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
            new_row["_source_idx"] = original_idx
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
            aug_info = {
                'original_index': int(original_idx),
                'original_path': str(img_path),
                'transformations': 'random_augmentation',
                'timestamp': pd.Timestamp.now().isoformat()
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            if output_dir:
                aug_filename = f"aug_{counter:06d}.jpg"
                aug_path = output_dir / aug_filename
                cv2.imwrite(str(aug_path), augmented_img)
                
                relative_path = f"augmented/{aug_filename}"
                new_row[image_col] = relative_path
            
                new_row["_augmented"] = True
                augmented.append(new_row)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Ç—å –∫ –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
                aug_info['augmented_path'] = str(aug_path)
                
                # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
                if original_df is not None:
                    # –í—ã—á–∏—Å–ª—è–µ–º –∏–Ω–¥–µ–∫—Å –≤ –±—É–¥—É—â–µ–º –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–º DataFrame
                    total_original_len = len(original_df)
                    current_aug_count = len(augmented)
                    # –ë—É–¥–µ–º –≤—ã—á–∏—Å–ª—è—Ç—å –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
                    self._augmented_info[len(original_df) + len(augmented) - 1] = aug_info
                
                counter += 1
            else:
                # –ë–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è ‚Äî —Ö—Ä–∞–Ω–∏–º –≤ –ø–∞–º—è—Ç–∏ (–¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤)
                new_row["_augmented_image"] = augmented_img
                new_row["_augmented"] = True
                augmented.append(new_row)
                
                # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
                if original_df is not None:
                    self._augmented_info[len(original_df) + len(augmented) - 1] = aug_info
                
                counter += 1
        
        return augmented, counter
    
    def get_albumentations_pipeline(self) -> Any:
        """–ü–æ–ª—É—á–∏—Ç—å Albumentations pipeline –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞"""
        return self._transform

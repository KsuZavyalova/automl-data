# examples/house_prices_complex.py
"""
–ü—Ä–∏–º–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ª–æ–∂–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ House Prices.
–° Kaggle: https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

from automl_data.core.forge import AutoForge
from automl_data.core.config import TabularConfig

def load_house_prices_data():
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ House Prices.
    –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–∫–∞—á–∏–≤–∞–µ–º —Å Kaggle API.
    """
    import os
    
    train_path = '/Users/kseniazavyalova/Downloads/house-prices-advanced-regression-techniques/train.csv'
    
    if os.path.exists(train_path):
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ {train_path}")
        df = pd.read_csv(train_path)

    return df


def analyze_dataset_complexity(df, target_col='SalePrice'):
    """–ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    print("\n" + "="*70)
    print("üîç –ê–ù–ê–õ–ò–ó –°–õ–û–ñ–ù–û–°–¢–ò –î–ê–¢–ê–°–ï–¢–ê")
    print("="*70)
    
    print(f"–†–∞–∑–º–µ—Ä: {df.shape[0]:,} —Å—Ç—Ä–æ–∫ √ó {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")
    print(f"–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {target_col}")
    
    # –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
    dtypes = df.dtypes.value_counts()
    print(f"\nüìä –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:")
    for dtype, count in dtypes.items():
        print(f"  {dtype}: {count} –∫–æ–ª–æ–Ω–æ–∫")
    
    # –ü—Ä–æ–ø—É—Å–∫–∏
    missing_total = df.isnull().sum().sum()
    missing_cols = (df.isnull().sum() > 0).sum()
    missing_percent = (missing_total / (df.shape[0] * df.shape[1])) * 100
    
    print(f"\n‚ùå –ü—Ä–æ–ø—É—Å–∫–∏:")
    print(f"  –í—Å–µ–≥–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤: {missing_total:,}")
    print(f"  –ö–æ–ª–æ–Ω–æ–∫ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏: {missing_cols}")
    print(f"  –ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤: {missing_percent:.1f}%")
    
    # –°–∞–º—ã–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    missing_by_col = df.isnull().sum().sort_values(ascending=False)
    print(f"\nüî• –¢–æ–ø-10 –∫–æ–ª–æ–Ω–æ–∫ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏:")
    for col, count in missing_by_col.head(10).items():
        percent = (count / len(df)) * 100
        print(f"  {col:25} {count:4} ({percent:5.1f}%)")
    
    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns
    print(f"\nüé≠ –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ: {len(categorical_cols)}")
    
    # –ê–Ω–∞–ª–∏–∑ –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
    print(f"\nüìà –ö–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö:")
    for col in categorical_cols[:5]:
        n_unique = df[col].nunique()
        print(f"  {col:25} {n_unique:3} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    print(f"\nüéØ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π ({target_col}):")
    target = df[target_col]
    print(f"  –¢–∏–ø: {target.dtype}")
    print(f"  –ú–∏–Ω–∏–º—É–º: {target.min():,.0f}")
    print(f"  –ú–∞–∫—Å–∏–º—É–º: {target.max():,.0f}")
    print(f"  –ú–µ–¥–∏–∞–Ω–∞: {target.median():,.0f}")
    print(f"  –°—Ä–µ–¥–Ω–µ–µ: {target.mean():,.0f}")
    print(f"  –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {target.std():,.0f}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤—ã–±—Ä–æ—Å—ã –≤ —Ü–µ–ª–µ–≤–æ–π
    from scipy import stats
    skewness = target.skew()
    kurtosis = target.kurtosis()
    print(f"  –ê—Å–∏–º–º–µ—Ç—Ä–∏—è: {skewness:.2f} {'‚ö†Ô∏è (—Å–∏–ª—å–Ω–∞—è –∞—Å–∏–º–º–µ—Ç—Ä–∏—è)' if abs(skewness) > 1 else ''}")
    print(f"  –≠–∫—Å—Ü–µ—Å—Å: {kurtosis:.2f}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏ (–±—ã—Å—Ç—Ä–∞—è)
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 1:
        corr_matrix = df[numeric_cols].corr().abs()
        high_corr = (corr_matrix > 0.8).sum().sum() - len(numeric_cols)  # –ò—Å–∫–ª—é—á–∞–µ–º –¥–∏–∞–≥–æ–Ω–∞–ª—å
        print(f"\nüîó –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å:")
        print(f"  –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–π > 0.8: {high_corr}")
    
    return df

def test_auto_forge_complex(df, target_col='SalePrice'):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ AutoForge –Ω–∞ —Å–ª–æ–∂–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ"""
    print("\n" + "="*70)
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï AUTOFORGE –ù–ê –°–õ–û–ñ–ù–û–ú –î–ê–¢–ê–°–ï–¢–ï")
    print("="*70)
    
    # 1. –ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç —Å –∞–≤—Ç–æ–Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    print("\n1. üìä –ë–∞–∑–æ–≤—ã–π AutoForge (–ø–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π):")
    forge_basic = AutoForge(
        target=target_col,
        task='auto',  # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–≥—Ä–µ—Å—Å–∏—é
        balance=True,  # –î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –Ω–µ –Ω—É–∂–Ω–∞
        verbose=True
    )
    
    try:
        result_basic = forge_basic.fit_transform(df)
        
        print(f"\n   ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –±–∞–∑–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        print(f"      ‚Ä¢ –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {df.shape}")
        print(f"      ‚Ä¢ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {result_basic.shape}")
        print(f"      ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: {result_basic.quality_score:.0%}")
        print(f"      ‚Ä¢ –®–∞–≥–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result_basic.steps}")
        print(f"      ‚Ä¢ –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {result_basic.execution_time:.2f} —Å–µ–∫")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ target –Ω–µ –ø–æ—Ç–µ—Ä—è–ª—Å—è
        assert result_basic.y is not None, "‚ùå Target –ø–æ—Ç–µ—Ä—è–Ω!"
        assert len(result_basic.y) == len(result_basic.data), "‚ùå Target –Ω–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω!"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        missing_after = result_basic.data.isnull().sum().sum()
        print(f"      ‚Ä¢ –ü—Ä–æ–ø—É—Å–∫–æ–≤ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {missing_after}")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –≤ –±–∞–∑–æ–≤–æ–º —Ä–µ–∂–∏–º–µ: {e}")
        import traceback
        traceback.print_exc()
    
    # 2. –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ç–µ—Å—Ç —Å –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    print("\n" + "="*70)
    print("2. ‚öôÔ∏è –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π AutoForge (–∫–∞—Å—Ç–æ–º–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è):")
    
    # –°–æ–∑–¥–∞–µ–º –∫–∞—Å—Ç–æ–º–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    tabular_config = TabularConfig(
        impute_strategy='iterative',  # –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –∏–º–ø—å—é—Ç–∞—Ü–∏—è –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–æ–ø—É—Å–∫–æ–≤
        scaling='robust',  # RobustScaler –∏–∑-–∑–∞ –≤—ã–±—Ä–æ—Å–æ–≤
        encode_strategy='target',  # Target encoding –¥–ª—è –≤—ã—Å–æ–∫–æ–π –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        max_onehot_cardinality=20,  # –ü–æ–≤—ã—à–∞–µ–º –ø–æ—Ä–æ–≥ –¥–ª—è one-hot
        outlier_method='isolation_forest',  # –ò–∑–æ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –ª–µ—Å –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –≤—ã–±—Ä–æ—Å–æ–≤
        outlier_action='clip'  # –û—Ç—Å–µ—á–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ —É–¥–∞–ª–µ–Ω–∏—è
    )
    
    forge_advanced = AutoForge(
        target=target_col,
        task='regression',
        tabular_config=tabular_config,
        test_size=0.2,
        random_state=42,
        verbose=True
    )
    
    try:
        result_advanced = forge_advanced.fit_transform(df)
        
        print(f"\n   ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        print(f"      ‚Ä¢ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {result_advanced.shape}")
        print(f"      ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: {result_advanced.quality_score:.0%}")
        print(f"      ‚Ä¢ –®–∞–≥–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result_advanced.steps}")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        print(f"\n   üîç –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑:")
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        X = result_advanced.X
        numeric_count = X.select_dtypes(include=[np.number]).shape[1]
        print(f"      ‚Ä¢ –ß–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {numeric_count}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        if result_advanced.y is not None:
            y = result_advanced.y
            print(f"      ‚Ä¢ Target: min={y.min():.0f}, max={y.max():.0f}, mean={y.mean():.0f}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏—è (—á–∞—Å—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è —Ü–µ–Ω)
            skew_before = df[target_col].skew()
            skew_after = y.skew()
            print(f"      ‚Ä¢ –ê—Å–∏–º–º–µ—Ç—Ä–∏—è target: –¥–æ={skew_before:.2f}, –ø–æ—Å–ª–µ={skew_after:.2f}")
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        print(f"\n   üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ AutoForge:")
        for i, rec in enumerate(result_advanced.recommendations[:5]):
            print(f"      {i+1}. {rec.get('type', 'info')}: {rec}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        result_advanced.save_report("house_prices_report.html")
        print(f"\n   üíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: house_prices_report.html")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        result_advanced.data.to_csv("house_prices_processed.csv", index=False)
        print(f"   üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: house_prices_processed.csv")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –≤ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–º —Ä–µ–∂–∏–º–µ: {e}")
        import traceback
        traceback.print_exc()
    
    # 3. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –º–æ–¥–µ–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
    print("\n" + "="*70)
    print("3. ü§ñ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê –ú–û–î–ï–õ–ò –†–ï–ì–†–ï–°–°–ò–ò")
    print("="*70)
    
    if 'result_advanced' in locals() and result_advanced.y is not None:
        from sklearn.model_selection import train_test_split
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
        import matplotlib.pyplot as plt
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        X, y = result_advanced.X, result_advanced.y
        
        # –†–∞–∑–¥–µ–ª—è–µ–º
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        print(f"\n   üìà –†–∞–∑–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏:")
        print(f"      ‚Ä¢ X_train: {X_train.shape}")
        print(f"      ‚Ä¢ X_test: {X_test.shape}")
        print(f"      ‚Ä¢ y_train: {y_train.shape}")
        print(f"      ‚Ä¢ y_test: {y_test.shape}")
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        print(f"\n   üîß –û–±—É—á–µ–Ω–∏–µ RandomForestRegressor...")
        model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        model.fit(X_train, y_train)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        y_pred = model.predict(X_test)
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        print(f"\n   üìä –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:")
        print(f"      ‚Ä¢ MSE:  {mse:,.0f}")
        print(f"      ‚Ä¢ RMSE: {rmse:,.0f}")
        print(f"      ‚Ä¢ MAE:  {mae:,.0f}")
        print(f"      ‚Ä¢ R¬≤:   {r2:.3f}")
        
        # –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        print(f"\n   üéØ –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        feature_importance = pd.DataFrame({
            'feature': X.columns,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        for i, row in enumerate(feature_importance.head(10).itertuples()):
            print(f"      {i+1:2}. {row.feature:30} {row.importance:.4f}")
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # 1. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        axes[0, 0].scatter(y_test, y_pred, alpha=0.5)
        axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
        axes[0, 0].set_xlabel('–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è')
        axes[0, 0].set_ylabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')
        axes[0, 0].set_title(f'–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è vs –§–∞–∫—Ç (R¬≤={r2:.3f})')
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. –û—à–∏–±–∫–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        errors = y_pred - y_test
        axes[0, 1].hist(errors, bins=30, edgecolor='black', alpha=0.7)
        axes[0, 1].axvline(x=0, color='r', linestyle='--')
        axes[0, 1].set_xlabel('–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è')
        axes[0, 1].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
        axes[0, 1].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        top_features = feature_importance.head(15)
        axes[1, 0].barh(range(len(top_features)), top_features['importance'].values)
        axes[1, 0].set_yticks(range(len(top_features)))
        axes[1, 0].set_yticklabels(top_features['feature'].values)
        axes[1, 0].invert_yaxis()
        axes[1, 0].set_xlabel('–í–∞–∂–Ω–æ—Å—Ç—å')
        axes[1, 0].set_title('–¢–æ–ø-15 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤')
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        axes[1, 1].hist(y, bins=30, edgecolor='black', alpha=0.7)
        axes[1, 1].set_xlabel('–¶–µ–Ω–∞ (SalePrice)')
        axes[1, 1].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
        axes[1, 1].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π')
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.suptitle('–ê–Ω–∞–ª–∏–∑ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ House Prices', fontsize=16, y=1.02)
        plt.tight_layout()
        plt.savefig('house_prices_regression_analysis.png', dpi=150, bbox_inches='tight')
        plt.show()
        
        print(f"\n   üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: house_prices_regression_analysis.png")




def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("="*70)
    print("üè† –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –°–õ–û–ñ–ù–û–ì–û –î–ê–¢–ê–°–ï–¢–ê HOUSE PRICES")
    print("="*70)
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = load_house_prices_data()
    
    # 2. –ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    df = analyze_dataset_complexity(df)
    
    # 3. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ AutoForge
    test_auto_forge_complex(df)
    
    print("\n" + "="*70)
    print("‚úÖ –ó–ê–í–ï–†–®–ï–ù–û! –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∞ —Å–ª–æ–∂–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç.")
    print("="*70)

if __name__ == "__main__":
    main()
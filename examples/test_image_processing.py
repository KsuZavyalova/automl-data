# test_image_processing_enhanced.py
"""
–£–ª—É—á—à–µ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ AutoForge –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
1. –¢–æ–ª—å–∫–æ –±–∏–±–ª–∏–æ—Ç–µ–∫—É automl_data –¥–ª—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
2. –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
3. CNN –Ω–∞ PyTorch –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
4. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á—ë—Ç–æ–≤
"""

import pandas as pd
import numpy as np
from pathlib import Path
import matplotlib
matplotlib.use('Agg')  # –î–ª—è —Å–µ—Ä–≤–µ—Ä–æ–≤ –±–µ–∑ GUI
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
from automl_data import AutoForge, DataContainer
from automl_data.core.config import ImageConfig

print("=" * 70)
print("üì∑ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –û–ë–†–ê–ë–û–¢–ö–ò –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô (–£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)")
print("=" * 70)

# ============================================
# 1. –°–û–ó–î–ê–ù–ò–ï –¢–ï–°–¢–û–í–û–ì–û –î–ê–¢–ê–°–ï–¢–ê (–°–û–ë–°–¢–í–ï–ù–ù–´–ô –ö–û–î)
# ============================================

def create_test_dataset_simple(output_dir="test_dataset"):
    """
    –°–æ–∑–¥–∞—ë—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–æ–ª—å–∫–æ automl_data.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç .jpg —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å OpenCV.
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True, parents=True)
    
    data = []
    
    print("\nüìÅ –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    
    # –°–æ–∑–¥–∞—ë–º —Å–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
    # –ö–ª–∞—Å—Å 0: 80% –¥–∞–Ω–Ω—ã—Ö, –ö–ª–∞—Å—Å 1: 20% –¥–∞–Ω–Ω—ã—Ö
    n_class0 = 80  # 80% (—É–º–µ–Ω—å—à–∏–ª–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞)
    n_class1 = 20  # 20%
    
    # –ö–ª–∞—Å—Å 0: –ö—Ä—É–≥–∏
    for i in range(n_class0):
        label = "circle"
        class_id = 0
        
        # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ numpy
        img = np.zeros((64, 64, 3), dtype=np.uint8)
        
        # –°–æ–∑–¥–∞—ë–º –∫—Ä—É–≥ —á–µ—Ä–µ–∑ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é
        y, x = np.ogrid[:64, :64]
        center_y, center_x = 32, 32
        radius = 20
        
        # –ú–∞—Å–∫–∞ –∫—Ä—É–≥–∞
        mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2
        
        # –ó–µ–ª—ë–Ω—ã–π –∫—Ä—É–≥ (BGR —Ñ–æ—Ä–º–∞—Ç)
        img[mask] = [0, 200, 0]  # BGR -> –∑–µ–ª—ë–Ω—ã–π
        
        # –î–æ–±–∞–≤–ª—è–µ–º —à—É–º
        noise = np.random.randint(-20, 20, (64, 64, 3), dtype=np.int16)
        img = np.clip(img.astype(np.int16) + noise, 0, 255).astype(np.uint8)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ JPG
        img_path = output_dir / f"class{class_id}_{i:03d}.jpg"
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º matplotlib –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–Ω–µ —Ç—Ä–µ–±—É–µ—Ç OpenCV)
        plt.imsave(str(img_path), img.astype(np.uint8))
        
        data.append({
            "image_id": f"circle_{i:03d}",
            "image_path": str(img_path.name),
            "label": label,
            "class_id": class_id,
            "dataset": "train"
        })
    
    # –ö–ª–∞—Å—Å 1: –ö–≤–∞–¥—Ä–∞—Ç—ã
    for i in range(n_class1):
        label = "square"
        class_id = 1
        
        # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ numpy
        img = np.zeros((64, 64, 3), dtype=np.uint8)
        
        # –°–æ–∑–¥–∞—ë–º –∫–≤–∞–¥—Ä–∞—Ç
        x1, y1 = 10, 10
        x2, y2 = 54, 54
        
        # –ö—Ä–∞—Å–Ω—ã–π –∫–≤–∞–¥—Ä–∞—Ç (BGR —Ñ–æ—Ä–º–∞—Ç)
        img[y1:y2, x1:x2] = [0, 0, 200]  # BGR -> –∫—Ä–∞—Å–Ω—ã–π
        
        # –î–æ–±–∞–≤–ª—è–µ–º —à—É–º
        noise = np.random.randint(-20, 20, (64, 64, 3), dtype=np.int16)
        img = np.clip(img.astype(np.int16) + noise, 0, 255).astype(np.uint8)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ JPG
        img_path = output_dir / f"class{class_id}_{i:03d}.jpg"
        plt.imsave(str(img_path), img.astype(np.uint8))
        
        data.append({
            "image_id": f"square_{i:03d}",
            "image_path": str(img_path.name),
            "label": label,
            "class_id": class_id,
            "dataset": "train"
        })
    
    df = pd.DataFrame(data)
    df.to_csv(output_dir / "metadata.csv", index=False)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(df)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print(f"   ‚Ä¢ –ö–ª–∞—Å—Å 0 (–∫—Ä—É–≥–∏): {n_class0} ({n_class0/len(df)*100:.1f}%)")
    print(f"   ‚Ä¢ –ö–ª–∞—Å—Å 1 (–∫–≤–∞–¥—Ä–∞—Ç—ã): {n_class1} ({n_class1/len(df)*100:.1f}%)")
    print(f"   ‚Ä¢ –î–∏—Å–±–∞–ª–∞–Ω—Å: {min(n_class0, n_class1)/max(n_class0, n_class1):.2%}")
    print(f"   ‚Ä¢ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_dir}")
    
    return df, output_dir

# ============================================
# 2. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø (–ú–ò–ù–ò–ú–ê–õ–¨–ù–ê–Ø)
# ============================================

def visualize_minimal(df, output_dir):
    """–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º automl_data"""
    print("\nüëÄ –ú–ò–ù–ò–ú–ê–õ–¨–ù–ê–Ø –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø")
    print("-" * 40)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º DataContainer –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    container = DataContainer(
        data=df.copy(),
        target_column="class_id",
        image_column="image_path",
        image_dir=output_dir
    )
    
    # –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫—É
    print("\nüìä –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–• –ß–ï–†–ï–ó DATACONTAINER:")
    print(f"   ‚Ä¢ –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö: {container.data_type.name}")
    print(f"   ‚Ä¢ –†–∞–∑–º–µ—Ä: {container.shape}")
    print(f"   ‚Ä¢ –ö–æ–ª–æ–Ω–∫–∏: {len(container.columns)}")
    print(f"   ‚Ä¢ –ß–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {len(container.numeric_columns)}")
    print(f"   ‚Ä¢ –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {len(container.categorical_columns)}")
    
    if container.class_distribution:
        print(f"\nüìà –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ö–õ–ê–°–°–û–í:")
        for class_name, count in container.class_distribution.items():
            percentage = count / len(container) * 100
            print(f"   ‚Ä¢ –ö–ª–∞—Å—Å {class_name}: {count} ({percentage:.1f}%)")
    
    print(f"\nüéØ –¶–ï–õ–ï–í–ê–Ø –ü–ï–†–ï–ú–ï–ù–ù–ê–Ø:")
    print(f"   ‚Ä¢ Target column: {container.target_column}")
    print(f"   ‚Ä¢ y shape: {container.y.shape if container.y is not None else 'N/A'}")
    
    return container

# ============================================
# 3. –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï AUTOFORGE (–ü–û–õ–ù–´–ô –¶–ò–ö–õ)
# ============================================

def test_full_cycle(df, output_dir):
    """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è AutoForge"""
    print("\n" + "=" * 60)
    print("‚öôÔ∏è –ü–û–õ–ù–´–ô –¶–ò–ö–õ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø AUTOFORGE")
    print("=" * 60)
    
    # –®–∞–≥ 1: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    print("\n1Ô∏è‚É£ –®–ê–ì: –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø")
    print("-" * 30)
    
    image_config = ImageConfig(
        # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥
        target_size=(64, 64),
        normalize=True,
        keep_aspect_ratio=False,  # –ü—Ä–æ—â–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        
        # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è (–≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∞)
        augment=True,
        augment_factor=2.0,  # –£–¥–≤–æ–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç
        
        # –ú–µ—Ç–æ–¥—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        horizontal_flip=True,
        rotation_range=15,
        brightness_range=(0.8, 1.2),
        contrast_range=(0.8, 1.2),
        zoom_range=(0.9, 1.1),
        
        # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞
        balance_classes=True
    )
    
    print(f"   ‚Ä¢ ImageConfig —Å–æ–∑–¥–∞–Ω")
    print(f"   ‚Ä¢ augment: {image_config.augment}")
    print(f"   ‚Ä¢ augment_factor: {image_config.augment_factor}")
    print(f"   ‚Ä¢ balance_classes: {image_config.balance_classes}")
    
    # –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ AutoForge
    print("\n2Ô∏è‚É£ –®–ê–ì: –°–û–ó–î–ê–ù–ò–ï AUTOFORGE")
    print("-" * 30)
    
    forge = AutoForge(
        target="class_id",
        image_column="image_path",
        image_dir=output_dir,
        task="classification",
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        image_config=image_config,
        
        # –û–±—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        balance=True,
        balance_threshold=0.5,  # –ü–æ—Ä–æ–≥ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        
        # –†–∞–∑–±–∏–µ–Ω–∏–µ
        test_size=0.2,
        stratify=True,
        random_state=42,
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        verbose=True
    )
    
    print(f"   ‚Ä¢ AutoForge —Å–æ–∑–¥–∞–Ω")
    print(f"   ‚Ä¢ target: {forge.config.target}")
    print(f"   ‚Ä¢ task: {forge.config.task.value}")
    
    # –®–∞–≥ 3: Fit
    print("\n3Ô∏è‚É£ –®–ê–ì: FIT (–ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•)")
    print("-" * 30)
    
    try:
        forge.fit(df)
        print(f"   ‚Ä¢ Pipeline –ø–æ—Å—Ç—Ä–æ–µ–Ω")
        print(f"   ‚Ä¢ –®–∞–≥–æ–≤ –≤ pipeline: {len(forge._pipeline) if forge._pipeline else 0}")
        print(f"   ‚Ä¢ Data type: {forge._data_type.name}")
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ fit: {e}")
        return None, None, None
    
    # –®–∞–≥ 4: Transform
    print("\n4Ô∏è‚É£ –®–ê–ì: TRANSFORM (–û–ë–†–ê–ë–û–¢–ö–ê)")
    print("-" * 30)
    
    try:
        result = forge.transform(df)
        print(f"   ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        print(f"   ‚Ä¢ –í—Ä–µ–º—è: {result.execution_time:.2f} —Å–µ–∫")
        print(f"   ‚Ä¢ –®–∞–≥–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {len(result.steps)}")
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ transform: {e}")
        return None, None, None
    
    # –®–∞–≥ 5: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n5Ô∏è‚É£ –®–ê–ì: –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("-" * 30)
    
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–†–ê–ë–û–¢–ö–ò:")
    print(f"   ‚Ä¢ –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(df)}")
    print(f"   ‚Ä¢ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(result.data)}")
    print(f"   ‚Ä¢ –£–≤–µ–ª–∏—á–µ–Ω–∏–µ: {len(result.data)/len(df):.2f}x")
    print(f"   ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: {result.quality_score:.1%}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
    if result.container.class_distribution:
        print(f"\nüìà –ë–ê–õ–ê–ù–°–ò–†–û–í–ö–ê –ö–õ–ê–°–°–û–í:")
        counts = list(result.container.class_distribution.values())
        
        for class_name, count in result.container.class_distribution.items():
            percentage = count / len(result.data) * 100
            print(f"   ‚Ä¢ –ö–ª–∞—Å—Å {class_name}: {count} ({percentage:.1f}%)")
        
        if len(counts) >= 2:
            ratio = min(counts) / max(counts)
            print(f"   ‚Ä¢ –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ: {ratio:.2f}")
            
            if ratio > 0.7:
                print(f"   ‚Ä¢ ‚úÖ –û—Ç–ª–∏—á–Ω–∞—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞")
            elif ratio > 0.5:
                print(f"   ‚Ä¢ ‚ö†Ô∏è  –°—Ä–µ–¥–Ω—è—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞")
            else:
                print(f"   ‚Ä¢ ‚ùå –ü–ª–æ—Ö–∞—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞")
    
    # –î–ï–¢–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–ò
    print(f"\nüîç –î–ï–¢–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–ò:")
    print(f"   ‚Ä¢ –ö–æ–ª–æ–Ω–∫–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ: {result.data.columns.tolist()}")
    
    if "_augmented" in result.data.columns:
        aug_count = result.data["_augmented"].sum()
        print(f"   ‚Ä¢ –ö–æ–ª–æ–Ω–∫–∞ '_augmented' –Ω–∞–π–¥–µ–Ω–∞!")
        print(f"   ‚Ä¢ True –∑–Ω–∞—á–µ–Ω–∏–π: {aug_count}")
        print(f"   ‚Ä¢ False –∑–Ω–∞—á–µ–Ω–∏–π: {len(result.data) - aug_count}")
        print(f"   ‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {aug_count/len(result.data)*100:.1f}%")
        
        if aug_count > 0:
            print(f"   ‚Ä¢ ‚úÖ –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–Ø –†–ê–ë–û–¢–ê–ï–¢!")
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫
            aug_samples = result.data[result.data["_augmented"]].head(2)
            print(f"   ‚Ä¢ –ü—Ä–∏–º–µ—Ä—ã –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫:")
            for idx, row in aug_samples.iterrows():
                print(f"      –°—Ç—Ä–æ–∫–∞ {idx}: class_id={row.get('class_id', 'N/A')}, label={row.get('label', 'N/A')}")
        else:
            print(f"   ‚Ä¢ ‚ùå –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–µ –¥–æ–±–∞–≤–∏–ª–∞ –¥–∞–Ω–Ω—ã–µ (aug_count=0)")
    else:
        print(f"   ‚Ä¢ ‚ùå –ö–æ–ª–æ–Ω–∫–∞ '_augmented' –Ω–µ —Å–æ–∑–¥–∞–Ω–∞")
        print(f"   ‚Ä¢ ImageAugmentor –Ω–µ –¥–æ–±–∞–≤–ª—è–µ—Ç –º–µ—Ç–∫–∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –¥—Ä—É–≥–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        new_columns = set(result.data.columns) - set(df.columns)
        if new_columns:
            print(f"   ‚Ä¢ –ù–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {new_columns}")
        else:
            print(f"   ‚Ä¢ –ù–µ—Ç –Ω–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ - –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–∏–∑–æ—à–ª–∞")
    
    # –®–∞–≥ 6: –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ train/test
    print("\n6Ô∏è‚É£ –®–ê–ì: –†–ê–ó–ë–ò–ï–ù–ò–ï –ù–ê TRAIN/TEST")
    print("-" * 30)
    
    try:
        X_train, X_test, y_train, y_test = result.get_splits(
            test_size=0.2,
            random_state=42,
            stratify=True
        )
        
        print(f"   ‚Ä¢ X_train: {X_train.shape}")
        print(f"   ‚Ä¢ X_test: {X_test.shape}")
        print(f"   ‚Ä¢ y_train: {y_train.shape if y_train is not None else 'N/A'}")
        print(f"   ‚Ä¢ y_test: {y_test.shape if y_test is not None else 'N/A'}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ —Å–ø–ª–∏—Ç–∞—Ö
        if y_train is not None:
            train_counts = y_train.value_counts()
            test_counts = y_test.value_counts() if y_test is not None else pd.Series()
            
            print(f"\nüìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –í SPLITS:")
            print(f"   ‚Ä¢ Train: {dict(train_counts)}")
            print(f"   ‚Ä¢ Test: {dict(test_counts)}")
        
        splits_info = {
            'X_train': X_train,
            'X_test': X_test,
            'y_train': y_train,
            'y_test': y_test
        }
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–∏–µ–Ω–∏–∏: {e}")
        splits_info = None
    
    return result, forge, splits_info

# ============================================
# 4. –£–õ–£–ß–®–ï–ù–ù–ê–Ø CNN –ù–ê PYTORCH
# ============================================

def test_cnn_enhanced(df_raw, result, splits_info, output_dir):  # –î–û–ë–ê–í–¨ output_dir –∑–¥–µ—Å—å
    """–£–ª—É—á—à–µ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ CNN —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    print("\n" + "=" * 60)
    print("üß† –£–õ–£–ß–®–ï–ù–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï CNN")
    print("=" * 60)
    
    try:
        # –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å PyTorch
        try:
            import torch
            import torch.nn as nn
            import torch.optim as optim
            from torch.utils.data import Dataset, DataLoader
            from torchvision import transforms
            import cv2
            TORCH_AVAILABLE = True
        except ImportError:
            print("‚ö†Ô∏è  PyTorch/torchvision –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º CNN —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ.")
            print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install torch torchvision opencv-python")
            return None
        
        print("A. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø CNN")
        print("-" * 30)
        
        # –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        class ImageDataset(Dataset):
            def __init__(self, df, image_dir, transform=None):
                self.df = df
                self.image_dir = Path(image_dir)
                self.transform = transform
            
            def __len__(self):
                return len(self.df)
            
            def __getitem__(self, idx):
                row = self.df.iloc[idx]
                img_path = self.image_dir / row["image_path"]
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                try:
                    img = cv2.imread(str(img_path))
                    if img is None:
                        # –°–æ–∑–¥–∞—ë–º –ø—É—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–æ—Å—å
                        img = np.zeros((64, 64, 3), dtype=np.uint8)
                    
                    # –†–µ—Å–∞–π–∑ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    if img.shape[:2] != (64, 64):
                        img = cv2.resize(img, (64, 64))
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º BGR -> RGB
                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    
                    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è [0, 1]
                    img = img.astype(np.float32) / 255.0
                    
                    # –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º –¥–ª—è PyTorch (H, W, C) -> (C, H, W)
                    img = np.transpose(img, (2, 0, 1))
                    
                    # –í —Ç–µ–Ω–∑–æ—Ä
                    img = torch.FloatTensor(img)
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
                    if self.transform:
                        img = self.transform(img)
                    
                    # –ú–µ—Ç–∫–∞
                    label = int(row["class_id"])
                    
                    return img, label
                    
                except Exception:
                    # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–µ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    img = torch.zeros((3, 64, 64))
                    label = 0
                    return img, label
        
        # –ü—Ä–æ—Å—Ç–∞—è CNN –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
        class SimpleCNN(nn.Module):
            def __init__(self, num_classes=2):
                super().__init__()
                self.features = nn.Sequential(
                    nn.Conv2d(3, 16, 3, padding=1),
                    nn.ReLU(),
                    nn.MaxPool2d(2),
                    nn.Conv2d(16, 32, 3, padding=1),
                    nn.ReLU(),
                    nn.MaxPool2d(2),
                    nn.Conv2d(32, 64, 3, padding=1),
                    nn.ReLU(),
                    nn.MaxPool2d(2)
                )
                self.classifier = nn.Sequential(
                    nn.Flatten(),
                    nn.Linear(64 * 8 * 8, 128),
                    nn.ReLU(),
                    nn.Dropout(0.3),
                    nn.Linear(128, num_classes)
                )
            
            def forward(self, x):
                x = self.features(x)
                x = self.classifier(x)
                return x
        
        # –§—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
        def train_one_epoch(model, dataloader, criterion, optimizer, device):
            model.train()
            running_loss = 0.0
            
            for batch_idx, (data, target) in enumerate(dataloader):
                data, target = data.to(device), target.to(device)
                
                optimizer.zero_grad()
                output = model(data)
                loss = criterion(output, target)
                loss.backward()
                optimizer.step()
                
                running_loss += loss.item()
            
            return running_loss / len(dataloader)
        
        # –§—É–Ω–∫—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        def validate(model, dataloader, criterion, device):
            model.eval()
            running_loss = 0.0
            correct = 0
            total = 0
            
            with torch.no_grad():
                for data, target in dataloader:
                    data, target = data.to(device), target.to(device)
                    output = model(data)
                    loss = criterion(output, target)
                    running_loss += loss.item()
                    
                    _, predicted = torch.max(output.data, 1)
                    total += target.size(0)
                    correct += (predicted == target).sum().item()
            
            accuracy = 100 * correct / total if total > 0 else 0
            return running_loss / len(dataloader), accuracy
        
        print("\nB. –¢–ï–°–¢ –ù–ê –°–´–†–´–• –î–ê–ù–ù–´–•")
        print("-" * 30)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
        from sklearn.model_selection import train_test_split
        
        train_raw, test_raw = train_test_split(
            df_raw, test_size=0.2, random_state=42, stratify=df_raw['class_id']
        )
        
        # –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç—ã
        transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.RandomHorizontalFlip(p=0.3),
            transforms.ToTensor(),
        ])
        
        train_dataset_raw = ImageDataset(train_raw, output_dir, transform=transform)
        test_dataset_raw = ImageDataset(test_raw, output_dir, transform=None)
        
        train_loader_raw = DataLoader(train_dataset_raw, batch_size=16, shuffle=True)
        test_loader_raw = DataLoader(test_dataset_raw, batch_size=16, shuffle=False)
        
        # –°–æ–∑–¥–∞—ë–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model_raw = SimpleCNN(num_classes=2).to(device)
        
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model_raw.parameters(), lr=0.001)
        
        print(f"   ‚Ä¢ –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
        print(f"   ‚Ä¢ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏: {sum(p.numel() for p in model_raw.parameters()):,}")
        
        # –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ (2 —ç–ø–æ—Ö–∏)
        raw_train_losses = []
        for epoch in range(2):
            train_loss = train_one_epoch(model_raw, train_loader_raw, criterion, optimizer, device)
            val_loss, val_acc = validate(model_raw, test_loader_raw, criterion, device)
            raw_train_losses.append(train_loss)
            
            print(f"   Epoch {epoch+1}/2: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")
        
        raw_final_loss = raw_train_losses[-1]
        
        print("\nC. –¢–ï–°–¢ –ù–ê –û–ë–†–ê–ë–û–¢–ê–ù–ù–´–• –î–ê–ù–ù–´–•")
        print("-" * 30)
        
        if splits_info and result is not None:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            X_train_proc = splits_info['X_train']
            X_test_proc = splits_info['X_test']
            y_train_proc = splits_info['y_train']
            y_test_proc = splits_info['y_test']
            
            # –°–æ–∑–¥–∞—ë–º DataFrame –∏–∑ —Å–ø–ª–∏—Ç–æ–≤
            train_proc = pd.concat([X_train_proc, y_train_proc], axis=1)
            test_proc = pd.concat([X_test_proc, y_test_proc], axis=1)
            
            # –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç—ã
            train_dataset_proc = ImageDataset(train_proc, output_dir, transform=transform)
            test_dataset_proc = ImageDataset(test_proc, output_dir, transform=None)
            
            train_loader_proc = DataLoader(train_dataset_proc, batch_size=16, shuffle=True)
            test_loader_proc = DataLoader(test_dataset_proc, batch_size=16, shuffle=False)
            
            # –°–æ–∑–¥–∞—ë–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            model_proc = SimpleCNN(num_classes=2).to(device)
            optimizer_proc = optim.Adam(model_proc.parameters(), lr=0.001)
            
            proc_train_losses = []
            for epoch in range(2):
                train_loss = train_one_epoch(model_proc, train_loader_proc, criterion, optimizer_proc, device)
                val_loss, val_acc = validate(model_proc, test_loader_proc, criterion, device)
                proc_train_losses.append(train_loss)
                
                print(f"   Epoch {epoch+1}/2: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")
            
            proc_final_loss = proc_train_losses[-1]
        else:
            print("   ‚ö†Ô∏è –ù–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            proc_final_loss = raw_final_loss
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
        print("\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        print("-" * 30)
        
        if proc_final_loss > 0:
            improvement = ((raw_final_loss - proc_final_loss) / raw_final_loss * 100)
        else:
            improvement = 0
        
        print(f"   ‚Ä¢ –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ - —Ñ–∏–Ω–∞–ª—å–Ω—ã–π loss: {raw_final_loss:.4f}")
        print(f"   ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ - —Ñ–∏–Ω–∞–ª—å–Ω—ã–π loss: {proc_final_loss:.4f}")
        print(f"   ‚Ä¢ –£–ª—É—á—à–µ–Ω–∏–µ: {improvement:+.1f}%")
        
        if improvement > 5:
            print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏–ª–∞ –æ–±—É—á–µ–Ω–∏–µ")
        elif improvement > 0:
            print(f"   ‚ö†Ô∏è  –ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ")
        else:
            print(f"   ‚ùå –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–ª—É—á—à–∏–ª–∞ –æ–±—É—á–µ–Ω–∏–µ")
        
        return {
            'raw_final_loss': raw_final_loss,
            'proc_final_loss': proc_final_loss,
            'improvement': improvement,
            'device': str(device)
        }
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤ CNN —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        return None



# ============================================
# 5. –°–û–ó–î–ê–ù–ò–ï –û–¢–ß–Å–¢–ê
# ============================================

def create_automl_report(df_raw, result, cnn_results=None):
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á—ë—Ç–∞"""
    print("\n" + "=" * 60)
    print("üìÑ –°–û–ó–î–ê–ù–ò–ï –û–¢–ß–Å–¢–ê")
    print("=" * 60)
    
    report_lines = []
    
    report_lines.append("=" * 70)
    report_lines.append("–û–¢–ß–Å–¢ –ü–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Æ AUTOFORGE")
    report_lines.append("=" * 70)
    report_lines.append(f"–î–∞—Ç–∞: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append("")
    
    if result is None:
        report_lines.append("‚ùå –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∏–∑-–∑–∞ –æ—à–∏–±–æ–∫")
        report_text = "\n".join(report_lines)
        
        with open("automl_forge_test_report.txt", "w", encoding="utf-8") as f:
            f.write(report_text)
        
        print("‚ö†Ô∏è –û—Ç—á—ë—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–∞—Ö")
        return report_text
    
    # 1. –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    report_lines.append("1. –û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø")
    report_lines.append("-" * 40)
    report_lines.append(f"‚Ä¢ –¢–∏–ø –∑–∞–¥–∞—á–∏: {result.config.task.value}")
    report_lines.append(f"‚Ä¢ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {result.config.target}")
    report_lines.append(f"‚Ä¢ –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(df_raw)}")
    report_lines.append(f"‚Ä¢ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {len(result.data)}")
    report_lines.append(f"‚Ä¢ –£–≤–µ–ª–∏—á–µ–Ω–∏–µ: {len(result.data)/len(df_raw):.2f}x")
    report_lines.append(f"‚Ä¢ –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.execution_time:.2f} —Å–µ–∫")
    report_lines.append(f"‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: {result.quality_score:.1%}")
    
    # 2. –®–∞–≥–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    report_lines.append("\n2. –®–ê–ì–ò –û–ë–†–ê–ë–û–¢–ö–ò")
    report_lines.append("-" * 40)
    for i, step in enumerate(result.steps, 1):
        report_lines.append(f"{i}. {step}")
    
    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
    report_lines.append("\n3. –ü–†–û–í–ï–†–ö–ê –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–ò")
    report_lines.append("-" * 40)
    
    if "_augmented" in result.data.columns:
        aug_count = result.data["_augmented"].sum()
        if aug_count > 0:
            report_lines.append(f"‚úÖ –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞")
            report_lines.append(f"   ‚Ä¢ –ê—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {aug_count}")
            report_lines.append(f"   ‚Ä¢ –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(result.data) - aug_count}")
            report_lines.append(f"   ‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {aug_count/len(result.data)*100:.1f}%")
        else:
            report_lines.append("‚ö†Ô∏è  –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞, –Ω–æ –Ω–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞")
    else:
        report_lines.append("‚ùå –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö")
    
    # 4. CNN —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if cnn_results:
        report_lines.append("\n4. –†–ï–ó–£–õ–¨–¢–ê–¢–´ CNN –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
        report_lines.append("-" * 40)
        report_lines.append(f"‚Ä¢ –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {cnn_results.get('device', 'N/A')}")
        report_lines.append(f"‚Ä¢ –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ - —Ñ–∏–Ω–∞–ª—å–Ω—ã–π loss: {cnn_results['raw_final_loss']:.4f}")
        report_lines.append(f"‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ - —Ñ–∏–Ω–∞–ª—å–Ω—ã–π loss: {cnn_results['proc_final_loss']:.4f}")
        report_lines.append(f"‚Ä¢ –£–ª—É—á—à–µ–Ω–∏–µ: {cnn_results['improvement']:+.1f}%")
        
        if cnn_results['improvement'] > 5:
            report_lines.append("‚Ä¢ –í–´–í–û–î: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏–ª–∞ –æ–±—É—á–µ–Ω–∏–µ CNN")
        elif cnn_results['improvement'] > 0:
            report_lines.append("‚Ä¢ –í–´–í–û–î: –ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è CNN")
        else:
            report_lines.append("‚Ä¢ –í–´–í–û–î: –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–ª—É—á—à–∏–ª–∞ –æ–±—É—á–µ–Ω–∏–µ CNN")
    
    # 5. –í—ã–≤–æ–¥—ã
    report_lines.append("\n5. –í–´–í–û–î–´")
    report_lines.append("-" * 40)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—Ç—É –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
    if "_augmented" in result.data.columns and result.data["_augmented"].sum() > 0:
        report_lines.append("‚úÖ –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–Ø –†–ê–ë–û–¢–ê–ï–¢ –ö–û–†–†–ï–ö–¢–ù–û")
        report_lines.append(f"   ‚Ä¢ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ —É—Å–ø–µ—à–Ω–æ —É–≤–µ–ª–∏—á–∏–ª–∞ –¥–∞—Ç–∞—Å–µ—Ç –≤ {len(result.data)/len(df_raw):.2f} —Ä–∞–∑–∞")
    else:
        report_lines.append("‚ùå –ü–†–û–ë–õ–ï–ú–ê –° –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–ï–ô")
        report_lines.append("   ‚Ä¢ ImageAugmentor –Ω–µ –¥–æ–±–∞–≤–∏–ª –Ω–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    # –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
    if result.quality_score > 0.8:
        report_lines.append("‚úÖ –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö")
    elif result.quality_score > 0.6:
        report_lines.append("‚ö†Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö")
    else:
        report_lines.append("‚ùå –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö")
    report_lines.append(f"   ‚Ä¢ –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {result.quality_score:.1%}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á—ë—Ç
    report_text = "\n".join(report_lines)
    
    with open("automl_forge_test_report.txt", "w", encoding="utf-8") as f:
        f.write(report_text)
    
    print(f"‚úÖ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: automl_forge_test_report.txt")
    
    # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é –≤–µ—Ä—Å–∏—é
    print("\nüìã –ö–†–ê–¢–ö–ò–ô –û–¢–ß–Å–¢:")
    print("-" * 40)
    for line in report_lines[:20]:  # –ü–µ—Ä–≤—ã–µ 20 —Å—Ç—Ä–æ–∫
        print(f"   {line}")
    
    return report_text

# ============================================
# 6. –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø
# ============================================

# ============================================
# 6. –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø
# ============================================

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("\n" + "=" * 70)
    print("üöÄ –ó–ê–ü–£–°–ö –£–õ–£–ß–®–ï–ù–ù–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø AUTOFORGE")
    print("=" * 70)
    
    try:
        # 1. –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
        print("\n1Ô∏è‚É£ –≠–¢–ê–ü: –°–û–ó–î–ê–ù–ò–ï –ú–ò–ù–ò–ú–ê–õ–¨–ù–û–ì–û –î–ê–¢–ê–°–ï–¢–ê")
        df_raw, output_dir = create_test_dataset_simple("automl_test_dataset")
        
        # 2. –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        print("\n2Ô∏è‚É£ –≠–¢–ê–ü: –ú–ò–ù–ò–ú–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó")
        container = visualize_minimal(df_raw, output_dir)
        
        # 3. –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª AutoForge
        print("\n3Ô∏è‚É£ –≠–¢–ê–ü: –ü–û–õ–ù–´–ô –¶–ò–ö–õ AUTOFORGE")
        result, forge, splits_info = test_full_cycle(df_raw, output_dir)
        
        # 4. CNN —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–ü–ï–†–ï–î–ê–ï–ú output_dir)
        print("\n4Ô∏è‚É£ –≠–¢–ê–ü: CNN –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï")
        cnn_results = test_cnn_enhanced(df_raw, result, splits_info, output_dir)  # –î–æ–±–∞–≤—å output_dir –∑–¥–µ—Å—å
        
        # 5. –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á—ë—Ç–∞
        print("\n5Ô∏è‚É£ –≠–¢–ê–ü: –°–û–ó–î–ê–ù–ò–ï –û–¢–ß–Å–¢–ê")
        report = create_automl_report(df_raw, result, cnn_results)
        
        # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ HTML –æ—Ç—á—ë—Ç–∞
        print("\n6Ô∏è‚É£ –≠–¢–ê–ü: HTML –û–¢–ß–Å–¢ AUTOFORGE")
        result.save_report("automl_forge_full_report.html")
        print("‚úÖ HTML –æ—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: automl_forge_full_report.html")
        
        # 7. –ò—Ç–æ–≥–∏
        print("\n" + "=" * 70)
        print("üéâ –£–õ–£–ß–®–ï–ù–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
        print("=" * 70)
        
        print("\nüìä –ö–õ–Æ–ß–ï–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print(f"   ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(df_raw)} ‚Üí {len(result.data)}")
        print(f"   ‚Ä¢ –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞: {len(result.data)/len(df_raw):.2f}x")
        print(f"   ‚Ä¢ –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.execution_time:.2f} —Å–µ–∫")
        print(f"   ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: {result.quality_score:.1%}")
        print(f"   ‚Ä¢ –®–∞–≥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(result.steps)}")
        
        if cnn_results:
            print(f"   ‚Ä¢ CNN —É–ª—É—á—à–µ–Ω–∏–µ: {cnn_results['improvement']:+.1f}%")
        
        print("\nüìÅ –°–û–ó–î–ê–ù–ù–´–ï –§–ê–ô–õ–´:")
        print("   1. automl_test_dataset/ - –¢–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç")
        print("   2. automl_forge_test_report.txt - –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á—ë—Ç")
        print("   3. automl_forge_full_report.html - HTML –æ—Ç—á—ë—Ç")
        
        print("\n‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ automl_data!")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        return False
# ============================================
# –ó–ê–ü–£–°–ö
# ============================================

if __name__ == "__main__":
    # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è matplotlib
    plt.rcParams['figure.figsize'] = (10, 6)
    plt.rcParams['font.size'] = 10
    
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    success = main()
    
    if success:
        print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print("   –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ automl_data —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.")
    else:
        print("\n‚ùå –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å —Å –æ—à–∏–±–∫–∞–º–∏.")
    
    print("\n" + "=" * 70)